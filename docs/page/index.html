<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>LifelongAgentBench: Evaluating LLM Agents as Lifelong Learners</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">
              <span class="icon-text">
                <span class="icon">
                  <img src="https://img.picui.cn/free/2025/05/21/682d857c0cb55.png" style="width: auto; height: 1em; vertical-align: middle; object-fit: contain;">
                </span>
                <span>LifelongAgentBench:<br>
                Evaluating LLM Agents as Lifelong Learners</span>
              </span>
            </h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://github.com/zzz47zzz" target="_blank">Junhao Zheng</a><sup>1*</sup>,</span>
              <span class="author-block">
                <a href="https://github.com/caixd-220529" target="_blank">Xidi Cai</a><sup>1*</sup>,</span>
              <span class="author-block">
                <a href="https://github.com/ChocoIee" target="_blank">Qiuke Li</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="https://bladedancer957.github.io/" target="_blank">Duzhen Zhang</a><sup>2</sup>,</span>
              <span class="author-block">
                <a href="https://github.com/zzli2022/zzli2022.github.io" target="_blank">Zhong-Zhi Li</a><sup>3</sup>,</span>
              <span class="author-block">
                <a href="https://faculty.ecnu.edu.cn/_s35/zyy2_12488/main.psp" target="_blank">Yingying Zhang</a><sup>4</sup>,</span>
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=Xl4E0CsAAAAJ&hl=en" target="_blank">Le Song</a><sup>2</sup>,</span>
              <span class="author-block">
                <a href="https://www2.scut.edu.cn/qianlima/" target="_blank">Qianli Ma</a><sup>1†</sup></span>
              </div>

                  <div class="is-size-5 publication-authors" style="max-width: 100%; margin: 0 auto;">
                    <span class="author-block"><sup>1</sup> South China University of Technology, <sup>2</sup>MBZUAI, <br><sup>3</sup>Chinese Academy of Sciences, <sup>4</sup>East China Normal University<br> 
                      <!-- Conferance name and year</span>
                    <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span> -->
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>


                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/YOUR REPO HERE" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser Image -->
<section class="hero teaser">
  <div class="container">
    <div class="hero-body">
      <img src="https://img.picui.cn/free/2025/05/21/682d857b6afe3.png" alt="Teaser Image" style="width: 70%; height: auto; display: block; margin: 0 auto;">
      <h2 class="subtitle has-text-centered" style="max-width: 90%; margin: 0 auto;">
        <span style="font-size: 1.2em;">LifelongAgentBench</span> is a unified benchmark and evaluation framework designed to systematically assess the lifelong learning capabilities of LLM-based agents. While lifelong learning is essential for intelligent agents operating in dynamic environments, current LLM agents remain stateless and struggle to accumulate or transfer knowledge over time. Existing benchmarks treat agents as static systems, lacking the means to evaluate continual learning. LifelongAgentBench addresses this gap by offering a skill-grounded task suite with interdependent challenges across three interactive environments—<span style="font-size: 1.1em;">Database</span>, <span style="font-size: 1.1em;">Operating System</span>, and <span style="font-size: 1.1em;">Knowledge Graph</span>. It features four key properties: task dependency, label verifiability, reproducibility, and modularity. 
      </h2>
    </div>
  </div>
</section>
<!-- End teaser Image -->

<!-- Paper abstract -->
<!-- <section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Lifelong learning is essential for intelligent agents operating in dynamic environments. Current large language model (LLM)-based agents, however, remain stateless and unable to accumulate or transfer knowledge over time. Existing benchmarks treat agents as static systems and fail to evaluate lifelong learning capabilities. We present <span style="font-size: 1.2em;">LifelongAgentBench</span>, the <span style="font-style: italic;">first</span> unified benchmark designed to systematically assess the lifelong learning ability of LLM agents. It provides skill-grounded, interdependent tasks across three interactive environments—Database, Operating System, and Knowledge Graph—with automatic label verification, reproducibility, and modular extensibility. Extensive experiments reveal that conventional experience replay has limited effectiveness for LLM agents due to irrelevant information and context length constraints. We further introduce a <span style="font-style: italic;">group self-consistency</span> mechanism that significantly improves lifelong learning performance. We hope <span style="font-size: 1.2em;">LifelongAgentBench</span> will advance the development of adaptive, memory-capable LLM agents.
          </p>
        </div>
      </div>
    </div>
  </div>
</section> -->
<!-- End paper abstract -->
<!-- Key Features Section -->

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full">
        <h2 class="title is-3">Datasets Design</h2>
      </div>
    </div>
  </div>
</section>
<!-- End Key Features Section -->
 <!-- Teaser Image -->
<section class="hero teaser">
  <div class="container">
    <div class="hero-body">
      <img src="https://img.picui.cn/free/2025/05/21/682d84c19309f.png" alt="Teaser Image" style="width: 80%; height: auto; display: block; margin: 0 auto;">
      <h2 class="subtitle has-text-centered" style="max-width: 92%; margin: 0 auto;">
        Partial Skill Distribution Examples from the Dataset<br>
        <span style="font-size: 1.2em;">LifelongAgentBench</span> features three environments—Database, Operating System, and Knowledge Graph—each with diverse skill sets to assess LLM agents’ lifelong learning. The Database environment includes 22 SQL skills such as filtering, grouping, and nested queries. The Operating System environment covers 29 Bash skills like file operations, user management, and text processing. The Knowledge Graph environment focuses on SPARQL tasks involving relation extraction and multi-step reasoning.
      </h2>
    </div>
  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full">
        <h2 class="title is-3">Group Self-Consistency</h2>
        <div class="content has-text-justified">
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End Key Features Section -->
 <!-- Teaser Image -->
<section class="hero teaser">
  <div class="container">
    <div class="hero-body">
      <img src="https://img.picui.cn/free/2025/05/21/682d84c124915.png" alt="Teaser Image" style="width: 70%; height: auto; display: block; margin: 0 auto;">
      <h2 class="subtitle has-text-centered" style="max-width: 92%; margin: 0 auto;">
        Experiments show that conventional experience replay underperforms due to context limits and irrelevant data. <br>To overcome this, a group self-consistency mechanism is introduced to enhance lifelong learning. <br><span style="font-size: 1.1em;">Group Self-Consistency</span> is a lightweight and scalable strategy to improve lifelong learning in LLM agents. It addresses the challenges of memory and inference overhead caused by experience replay by partitioning retrieved experiences into smaller groups. Each group is processed independently, and final predictions are aggregated through self-consistency voting. This approach significantly reduces input length while preserving prediction accuracy, leading to more stable and efficient learning across diverse environments. Its simplicity and generalizability make it a promising solution for memory-constrained lifelong learning scenarios.
      </h2>
    </div>
  </div>
</section>
<section class="hero teaser">
  <div class="container">
    <div class="hero-body">
      <img src="https://img.picui.cn/free/2025/05/21/682d85c4ea565.png" alt="Teaser Image" style="width: 85%; height: auto; display: block; margin: 0 auto;">
      <h2 class="subtitle has-text-centered" style="max-width: 92%; margin: 0 auto;">
        Comparison of the accuracy (average input tokens) under different group self-consistency settings.
      </h2>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full">
        <h2 class="title is-3">Related Work</h2>
      </div>
    </div>
  </div>
</section>
<!-- End Key Features Section -->
 <!-- Teaser Image -->
<section class="hero teaser">
  <div class="container">
    <div class="hero-body">
      <img src="static\images\Comparison.png" alt="Teaser Image" style="width: 92%; height: auto; display: block; margin: 0 auto;">
      <h2 class="subtitle has-text-centered" style="max-width: 92%; margin: 0 auto;">
        Comparison between LifelongAgentBench and existing benchmarks. †: highlights label error issues in WebArena. <br><span style="font-size: 1.2em;">LifelongAgentBench</span> is the <span style="font-size: 1.1em;font-style:oblique;">first</span> unified benchmark specifically designed to evaluate lifelong learning in LLM-based agents across realistic and diverse environments. It addresses critical limitations in prior benchmarks, such as lack of task dependency modeling, label verifiability, and reproducibility. The benchmark features three interactive environments—Database, Operating System, and Knowledge Graph—that assess agents’ abilities to acquire, transfer, and retain skills over long task sequences.
      </h2>
    </div>
  </div>
</section>








<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>BibTex Code Here</code></pre>
    </div>
</section>
<!--End BibTex citation -->


<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
